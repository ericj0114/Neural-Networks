{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://github.com/Narasimha1997/Blood-Cell-type-identification-using-CNN-classifier\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, MaxPool2D, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications import vgg16\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img \n",
    "from sklearn.metrics import auc, roc_curve, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4800 images belonging to 4 classes.\n",
      "Found 960 images belonging to 4 classes.\n",
      "Epoch 1/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 1.3905 - acc: 0.2658Epoch 00000: val_loss improved from inf to 6.12882, saving model to model_weights.h5\n",
      "300/300 [==============================] - 82s - loss: 1.3905 - acc: 0.2656 - val_loss: 6.1288 - val_acc: 0.2760\n",
      "Epoch 2/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 1.3413 - acc: 0.3464Epoch 00001: val_loss did not improve\n",
      "300/300 [==============================] - 80s - loss: 1.3411 - acc: 0.3465 - val_loss: 9.1488 - val_acc: 0.4255\n",
      "Epoch 3/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 1.2350 - acc: 0.4169Epoch 00002: val_loss did not improve\n",
      "300/300 [==============================] - 79s - loss: 1.2345 - acc: 0.4173 - val_loss: 10.0055 - val_acc: 0.3776\n",
      "Epoch 4/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 2.0379 - acc: 0.4749Epoch 00003: val_loss did not improve\n",
      "300/300 [==============================] - 78s - loss: 2.0345 - acc: 0.4752 - val_loss: 10.2807 - val_acc: 0.3609\n",
      "Epoch 5/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.9474 - acc: 0.5777Epoch 00004: val_loss did not improve\n",
      "300/300 [==============================] - 79s - loss: 0.9466 - acc: 0.5778 - val_loss: 8.1368 - val_acc: 0.4875\n",
      "Epoch 6/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.7683 - acc: 0.6541Epoch 00005: val_loss did not improve\n",
      "300/300 [==============================] - 79s - loss: 0.7681 - acc: 0.6541 - val_loss: 7.0780 - val_acc: 0.5573\n",
      "Epoch 7/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.6453 - acc: 0.7030Epoch 00006: val_loss improved from 6.12882 to 5.63857, saving model to model_weights.h5\n",
      "300/300 [==============================] - 79s - loss: 0.6448 - acc: 0.7034 - val_loss: 5.6386 - val_acc: 0.6464\n",
      "Epoch 8/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.6085 - acc: 0.7222Epoch 00007: val_loss improved from 5.63857 to 5.23406, saving model to model_weights.h5\n",
      "300/300 [==============================] - 79s - loss: 0.6088 - acc: 0.7222 - val_loss: 5.2341 - val_acc: 0.6708\n",
      "Epoch 9/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.5353 - acc: 0.7608Epoch 00008: val_loss did not improve\n",
      "300/300 [==============================] - 79s - loss: 0.5341 - acc: 0.7614 - val_loss: 6.6652 - val_acc: 0.5849\n",
      "Epoch 10/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.5306 - acc: 0.7727Epoch 00009: val_loss improved from 5.23406 to 3.57546, saving model to model_weights.h5\n",
      "300/300 [==============================] - 80s - loss: 0.5306 - acc: 0.7726 - val_loss: 3.5755 - val_acc: 0.7750\n",
      "Epoch 11/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.4456 - acc: 0.8108Epoch 00010: val_loss did not improve\n",
      "300/300 [==============================] - 79s - loss: 0.4453 - acc: 0.8110 - val_loss: 5.3918 - val_acc: 0.6651\n",
      "Epoch 12/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.4070 - acc: 0.8294Epoch 00011: val_loss did not improve\n",
      "300/300 [==============================] - 79s - loss: 0.4068 - acc: 0.8295 - val_loss: 4.5345 - val_acc: 0.7177\n",
      "Epoch 13/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.3738 - acc: 0.8426Epoch 00012: val_loss improved from 3.57546 to 3.45657, saving model to model_weights.h5\n",
      "300/300 [==============================] - 80s - loss: 0.3732 - acc: 0.8430 - val_loss: 3.4566 - val_acc: 0.7828\n",
      "Epoch 14/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.3437 - acc: 0.8602Epoch 00013: val_loss did not improve\n",
      "300/300 [==============================] - 79s - loss: 0.3435 - acc: 0.8602 - val_loss: 5.0382 - val_acc: 0.6870\n",
      "Epoch 15/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.3209 - acc: 0.8698Epoch 00014: val_loss did not improve\n",
      "300/300 [==============================] - 79s - loss: 0.3203 - acc: 0.8700 - val_loss: 4.8789 - val_acc: 0.6969\n",
      "Epoch 16/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.3251 - acc: 0.8680Epoch 00015: val_loss did not improve\n",
      "300/300 [==============================] - 78s - loss: 0.3249 - acc: 0.8681 - val_loss: 8.4886 - val_acc: 0.4724\n",
      "Epoch 17/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.3051 - acc: 0.8792Epoch 00016: val_loss did not improve\n",
      "300/300 [==============================] - 79s - loss: 0.3043 - acc: 0.8796 - val_loss: 5.3917 - val_acc: 0.6646\n",
      "Epoch 18/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.2742 - acc: 0.8934Epoch 00017: val_loss did not improve\n",
      "300/300 [==============================] - 79s - loss: 0.2737 - acc: 0.8936 - val_loss: 10.3105 - val_acc: 0.3599\n",
      "Epoch 19/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.3230 - acc: 0.8802Epoch 00018: val_loss did not improve\n",
      "300/300 [==============================] - 78s - loss: 0.3257 - acc: 0.8792 - val_loss: 4.5314 - val_acc: 0.7172\n",
      "Epoch 20/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.2540 - acc: 0.9000Epoch 00019: val_loss did not improve\n",
      "300/300 [==============================] - 78s - loss: 0.2537 - acc: 0.9000 - val_loss: 3.5169 - val_acc: 0.7807\n",
      "Epoch 00019: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f086a4b5ba8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "img_width, img_height = 120, 160\n",
    "\n",
    "train_dir = 'cell/data/train'\n",
    "val_dir = 'cell/data/val'\n",
    "test_dir = 'cell/data/test_set'\n",
    "model_weights_dir = 'model_weights.h5'\n",
    "\n",
    "#generators to upload training, validation, and test images\n",
    "train_generator = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)\n",
    "\n",
    "\n",
    "train_data = train_generator.flow_from_directory(\n",
    "    shuffle = True,\n",
    "    batch_size = 32,\n",
    "    target_size = (img_width, img_height),\n",
    "    directory = train_dir)\n",
    "\n",
    "num_classes = len(train_data.class_indices) \n",
    "\n",
    "val_generator = ImageDataGenerator(\n",
    "                rescale= 1/.255)\n",
    "\n",
    "val_data = val_generator.flow_from_directory(\n",
    "    shuffle = True,\n",
    "    batch_size = 32,\n",
    "    target_size = (img_width, img_height),\n",
    "    directory = val_dir)\n",
    "\n",
    "#create convolutional neural network to classify cell images\n",
    "def model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(80, (3,3), activation = 'relu', input_shape = (img_width, img_height, 3)))\n",
    "    model.add(Conv2D(64, (3,3), activation = 'relu', input_shape = (img_width, img_height, 3)))\n",
    "    model.add(MaxPool2D(pool_size = (2,2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adadelta', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#used to stop training if NN shows no improvement for 6 epochs\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=6, verbose=1)\n",
    "    \n",
    "#checks each epoch as it runs and saves the weight file from the model with the lowest validation loss\n",
    "checkpointer = ModelCheckpoint(filepath=model_weights_dir, verbose=1, save_best_only=True)\n",
    "\n",
    "#fit model to the data\n",
    "nn = model()\n",
    "nn.fit_generator(train_data, steps_per_epoch = len(train_data.filenames)//batch_size, \n",
    "                 validation_data=val_data,\n",
    "                 validation_steps= len(val_data.filenames) // batch_size, \n",
    "                 epochs = 30,\n",
    "                 callbacks = [early_stop, checkpointer],\n",
    "                 verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test images into array for testing model predictions\n",
    "all_images = []\n",
    "for sub in sorted(os.listdir(test_dir)):\n",
    "    for image_path in os.listdir(test_dir + '/' + sub):\n",
    "        image = load_img(test_dir + '/' + sub + '/' + image_path, target_size=(img_width, img_height))\n",
    "        image = img_to_array(image)\n",
    "        all_images.append(image)\n",
    "all_test = np.array(all_images)\n",
    "\n",
    "#must divide image array by 255 due to 'rescale=1./255' in ImageDataGenerator; rescales all image values from\n",
    "#[0-255] range to [0-1.0] range\n",
    "all_test = all_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 4 classes.\n",
      "352/400 [=========================>....] - ETA: 0s\n",
      "\n",
      "[[ 73   0   0  27]\n",
      " [  0 100   0   0]\n",
      " [  0   1  98   1]\n",
      " [  3   2   2  93]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.73      0.83       100\n",
      "          1       0.97      1.00      0.99       100\n",
      "          2       0.98      0.98      0.98       100\n",
      "          3       0.77      0.93      0.84       100\n",
      "\n",
      "avg / total       0.92      0.91      0.91       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generate true labels for test data\n",
    "test_label_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "test_label_generator = test_label_datagen.flow_from_directory(  \n",
    "    test_dir,  \n",
    "    target_size=(img_width, img_height),  \n",
    "    batch_size=batch_size,  \n",
    "    class_mode=None,  \n",
    "    shuffle=False)  \n",
    "\n",
    "test_labels = test_label_generator.classes\n",
    "\n",
    "#use trained model to predict class of each image in the test set\n",
    "all_pred = nn.predict(all_test)\n",
    "all_pred_class = nn.predict_classes(all_test)\n",
    "\n",
    "print('\\n')\n",
    "print(confusion_matrix(test_labels, all_pred_class))\n",
    "print(classification_report(test_labels, all_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Eric)",
   "language": "python",
   "name": "eric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
